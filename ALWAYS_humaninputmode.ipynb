{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOrgKfbVBoPlifdJ8dBSnYo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/balkrishnapdl/Autogen-Framework/blob/main/ALWAYS_humaninputmode.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# try:\n",
        "#     import dolfin\n",
        "# except ImportError:\n",
        "#     !wget \"https://fem-on-colab.github.io/releases/fenics-install-real.sh\" -O \"/tmp/fenics-install.sh\" && bash \"/tmp/fenics-install.sh\"\n",
        "#     import dolfin"
      ],
      "metadata": {
        "id": "scvfGpDi7yhl"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    import chromadb\n",
        "except ImportError:\n",
        "    !pip install chromadb==0.4.15\n",
        "    import chromadb\n",
        "\n",
        "try:\n",
        "    import tiktoken\n",
        "except ImportError:\n",
        "    !pip install tiktoken==0.5.1\n",
        "    import tiktoken\n",
        "\n",
        "try:\n",
        "    import pypdf\n",
        "except ImportError:\n",
        "    !pip install pypdf==3.17.0\n",
        "    import pypdf"
      ],
      "metadata": {
        "id": "PBI_M4CT7zpX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pyautogen[gemini]"
      ],
      "metadata": {
        "id": "P1lsPqYm75iu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from typing import Any, Callable, Dict, List, Optional, Tuple, Type, Union\n",
        "\n",
        "import chromadb\n",
        "from PIL import Image\n",
        "from termcolor import colored\n",
        "\n",
        "import autogen\n",
        "from autogen import Agent, AssistantAgent, ConversableAgent, UserProxyAgent\n",
        "from autogen.agentchat.contrib.img_utils import _to_pil, get_image_data\n",
        "from autogen.agentchat.contrib.multimodal_conversable_agent import MultimodalConversableAgent\n",
        "from autogen.agentchat.contrib.retrieve_assistant_agent import RetrieveAssistantAgent\n",
        "from autogen.agentchat.contrib.retrieve_user_proxy_agent import RetrieveUserProxyAgent\n",
        "from autogen.code_utils import DEFAULT_MODEL, UNKNOWN, content_str, execute_code, extract_code, infer_lang"
      ],
      "metadata": {
        "id": "laPcZTmV8jew"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from google.colab import userdata\n",
        "geminiapi=userdata.get('GEMINI_API_KEY')\n",
        "config_list_gemini = [\n",
        "     {\n",
        "        \"model\": \"gemini-pro\",\n",
        "        \"api_key\": geminiapi,\n",
        "        \"api_type\": \"google\"\n",
        "    }\n",
        "]"
      ],
      "metadata": {
        "id": "w0-98Dax8uGc"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "gemini_config = {\n",
        "    \"seed\": 25,  # change the seed for different trials\n",
        "    \"temperature\": 0,\n",
        "    \"config_list\": config_list_gemini,\n",
        "    \"request_timeout\": 600,\n",
        "    \"retry_wait_time\": 120,\n",
        "}"
      ],
      "metadata": {
        "id": "MfDEGqfA80UF"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent_with_number = ConversableAgent(\n",
        "    name=\"agent_with_number\",\n",
        "    system_message=\"You are playing a game of guess-my-number. You have the \"\n",
        "    \"number 53 in your mind, and I will try to guess it. \"\n",
        "    \"If I guess too high, say 'too high', if I guess too low, say 'too low'. \",\n",
        "    llm_config=gemini_config,\n",
        "    is_termination_msg=lambda msg: \"53\" in msg[\"content\"],  # terminate if the number is guessed by the other agent\n",
        "    human_input_mode=\"NEVER\")\n",
        "Ramey = ConversableAgent(\n",
        "    name=\"Ramey\",\n",
        "    llm_config=False, #no LLM used for human Proxy\n",
        "    human_input_mode=\"ALWAYS\", # Never ask for human input.\n",
        ")"
      ],
      "metadata": {
        "id": "z7yb7mbt8-_O"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent_with_number.initiate_chat(\n",
        "    Ramey,\n",
        "    message=\"I have a number between 1 and 100. Guess it!\",\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 503
        },
        "id": "0gvXgJug9pvd",
        "outputId": "6e089cdc-c7d9-40b9-9a5e-92c9839b2077"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "agent_with_number (to Ramey):\n",
            "\n",
            "I have a number between 1 and 100. Guess it!\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Replying as Ramey. Provide feedback to agent_with_number. Press enter to skip and use auto-reply, or type 'exit' to end the conversation: 8\n",
            "Ramey (to agent_with_number):\n",
            "\n",
            "8\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "agent_with_number (to Ramey):\n",
            "\n",
            "Too low.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Replying as Ramey. Provide feedback to agent_with_number. Press enter to skip and use auto-reply, or type 'exit' to end the conversation: 53\n",
            "Ramey (to agent_with_number):\n",
            "\n",
            "53\n",
            "\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ChatResult(chat_id=None, chat_history=[{'content': 'I have a number between 1 and 100. Guess it!', 'role': 'assistant', 'name': 'agent_with_number'}, {'content': '8', 'role': 'user', 'name': 'Ramey'}, {'content': 'Too low.', 'role': 'assistant', 'name': 'agent_with_number'}, {'content': '53', 'role': 'user', 'name': 'Ramey'}], summary='53', cost={'usage_including_cached_inference': {'total_cost': 4.15e-05, 'gemini-pro': {'cost': 4.15e-05, 'prompt_tokens': 74, 'completion_tokens': 3, 'total_tokens': 77}}, 'usage_excluding_cached_inference': {'total_cost': 4.15e-05, 'gemini-pro': {'cost': 4.15e-05, 'prompt_tokens': 74, 'completion_tokens': 3, 'total_tokens': 77}}}, human_input=[])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yM0ukel9-Cp9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}