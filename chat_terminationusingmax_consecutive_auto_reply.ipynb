{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPQl1dmwNu2ZbOfumDgAgFd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/balkrishnapdl/Autogen-Framework/blob/main/chat_terminationusingmax_consecutive_auto_reply.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# try:\n",
        "#     import dolfin\n",
        "# except ImportError:\n",
        "#     !wget \"https://fem-on-colab.github.io/releases/fenics-install-real.sh\" -O \"/tmp/fenics-install.sh\" && bash \"/tmp/fenics-install.sh\"\n",
        "#     import dolfin"
      ],
      "metadata": {
        "id": "scvfGpDi7yhl"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    import chromadb\n",
        "except ImportError:\n",
        "    !pip install chromadb==0.4.15\n",
        "    import chromadb\n",
        "\n",
        "try:\n",
        "    import tiktoken\n",
        "except ImportError:\n",
        "    !pip install tiktoken==0.5.1\n",
        "    import tiktoken\n",
        "\n",
        "try:\n",
        "    import pypdf\n",
        "except ImportError:\n",
        "    !pip install pypdf==3.17.0\n",
        "    import pypdf"
      ],
      "metadata": {
        "id": "PBI_M4CT7zpX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pyautogen[gemini]"
      ],
      "metadata": {
        "id": "P1lsPqYm75iu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from typing import Any, Callable, Dict, List, Optional, Tuple, Type, Union\n",
        "\n",
        "import chromadb\n",
        "from PIL import Image\n",
        "from termcolor import colored\n",
        "\n",
        "import autogen\n",
        "from autogen import Agent, AssistantAgent, ConversableAgent, UserProxyAgent\n",
        "from autogen.agentchat.contrib.img_utils import _to_pil, get_image_data\n",
        "from autogen.agentchat.contrib.multimodal_conversable_agent import MultimodalConversableAgent\n",
        "from autogen.agentchat.contrib.retrieve_assistant_agent import RetrieveAssistantAgent\n",
        "from autogen.agentchat.contrib.retrieve_user_proxy_agent import RetrieveUserProxyAgent\n",
        "from autogen.code_utils import DEFAULT_MODEL, UNKNOWN, content_str, execute_code, extract_code, infer_lang"
      ],
      "metadata": {
        "id": "laPcZTmV8jew"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from google.colab import userdata\n",
        "geminiapi=userdata.get('GEMINI_API_KEY')\n",
        "config_list_gemini = [\n",
        "     {\n",
        "        \"model\": \"gemini-pro\",\n",
        "        \"api_key\": geminiapi,\n",
        "        \"api_type\": \"google\"\n",
        "    }\n",
        "]"
      ],
      "metadata": {
        "id": "w0-98Dax8uGc"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "gemini_config = {\n",
        "    \"seed\": 25,  # change the seed for different trials\n",
        "    \"temperature\": 0,\n",
        "    \"config_list\": config_list_gemini,\n",
        "    \"request_timeout\": 600,\n",
        "    \"retry_wait_time\": 120,\n",
        "}"
      ],
      "metadata": {
        "id": "MfDEGqfA80UF"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cathy = ConversableAgent(\n",
        "    name=\"cathy\",\n",
        "    system_message=\"Your name is Cathy and you are a part of a duo of comedians.\",\n",
        "    llm_config=gemini_config,\n",
        "    human_input_mode=\"NEVER\")\n",
        "\n",
        "joe = ConversableAgent(\n",
        "    name=\"joe\",\n",
        "    system_message=\"Your name is Joe and you are a part of a duo of comedians.\",\n",
        "    llm_config=gemini_config,\n",
        "    human_input_mode=\"NEVER\", # Never ask for human input.\n",
        "    max_consecutive_auto_reply=1,\n",
        ")"
      ],
      "metadata": {
        "id": "z7yb7mbt8-_O"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "joe.initiate_chat(\n",
        "    cathy,\n",
        "    message=\"Cathy, tell me a joke.\",\n",
        "    max_turns=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "0gvXgJug9pvd",
        "outputId": "fa98469d-79f4-4156-daa4-c2fae14c2ddb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "joe (to cathy):\n",
            "\n",
            "Cathy, tell me a joke.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "cathy (to joe):\n",
            "\n",
            "Why did the scarecrow win an award?\n",
            "\n",
            "Because he was outstanding in his field!\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "joe (to cathy):\n",
            "\n",
            "That's a great joke, Cathy! I love it!\n",
            "\n",
            "Hey everyone, did you hear about the scarecrow who won an award?\n",
            "\n",
            "(Pause for laughter)\n",
            "\n",
            "Yeah, he was outstanding in his field!\n",
            "\n",
            "(Pause for more laughter)\n",
            "\n",
            "I'm telling you, that scarecrow was a real standout. He was head and shoulders above the rest.\n",
            "\n",
            "(Pause for even more laughter)\n",
            "\n",
            "Okay, okay, I'll stop with the scarecrow jokes. But seriously, that was a great joke, Cathy. Thanks for sharing it with me.\n",
            "\n",
            "Now, what do you say we move on to the next joke? I've got a really funny one about a talking dog. Are you ready for it?\n",
            "\n",
            "(Pause for audience response)\n",
            "\n",
            "Okay, here it goes:\n",
            "\n",
            "What do you call a dog that can talk?\n",
            "\n",
            "(Pause for laughter)\n",
            "\n",
            "A conversa-dog!\n",
            "\n",
            "(Pause for more laughter)\n",
            "\n",
            "Get it? Conversa-dog? Because he can talk?\n",
            "\n",
            "(Pause for even more laughter)\n",
            "\n",
            "I'm telling you, this joke is a real knee-slapper. I can't believe I didn't think of it sooner.\n",
            "\n",
            "Okay, okay, I'll stop with the dog jokes. But seriously, that was a great joke, Cathy. Thanks for sharing it with me.\n",
            "\n",
            "Now, what do you say we take a break? I'm getting a little thirsty.\n",
            "\n",
            "(Pause for audience response)\n",
            "\n",
            "Okay, we'll be back in a few minutes with more jokes. In the meantime, feel free to get up and stretch your legs. Or go to the bathroom. Or whatever you need to do.\n",
            "\n",
            "We'll be back soon!\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "cathy (to joe):\n",
            "\n",
            "I'm glad you enjoyed the joke! I love telling jokes, and it's always great to see people laugh.\n",
            "\n",
            "I'm also happy to hear that you have a joke to share with me. I'm always looking for new jokes to add to my repertoire.\n",
            "\n",
            "Your joke about the talking dog is very funny! I especially like the way you played on the words \"conversa\" and \"dog.\" It's a very clever joke.\n",
            "\n",
            "I'm also glad to hear that you're enjoying our comedy duo. We work hard to make our shows funny and entertaining, and it's always great to get positive feedback from our audience.\n",
            "\n",
            "I'm looking forward to hearing more of your jokes in the future. Keep up the good work!\n",
            "\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ChatResult(chat_id=None, chat_history=[{'content': 'Cathy, tell me a joke.', 'role': 'assistant', 'name': 'joe'}, {'content': 'Why did the scarecrow win an award?\\n\\nBecause he was outstanding in his field!', 'role': 'user', 'name': 'cathy'}, {'content': \"That's a great joke, Cathy! I love it!\\n\\nHey everyone, did you hear about the scarecrow who won an award?\\n\\n(Pause for laughter)\\n\\nYeah, he was outstanding in his field!\\n\\n(Pause for more laughter)\\n\\nI'm telling you, that scarecrow was a real standout. He was head and shoulders above the rest.\\n\\n(Pause for even more laughter)\\n\\nOkay, okay, I'll stop with the scarecrow jokes. But seriously, that was a great joke, Cathy. Thanks for sharing it with me.\\n\\nNow, what do you say we move on to the next joke? I've got a really funny one about a talking dog. Are you ready for it?\\n\\n(Pause for audience response)\\n\\nOkay, here it goes:\\n\\nWhat do you call a dog that can talk?\\n\\n(Pause for laughter)\\n\\nA conversa-dog!\\n\\n(Pause for more laughter)\\n\\nGet it? Conversa-dog? Because he can talk?\\n\\n(Pause for even more laughter)\\n\\nI'm telling you, this joke is a real knee-slapper. I can't believe I didn't think of it sooner.\\n\\nOkay, okay, I'll stop with the dog jokes. But seriously, that was a great joke, Cathy. Thanks for sharing it with me.\\n\\nNow, what do you say we take a break? I'm getting a little thirsty.\\n\\n(Pause for audience response)\\n\\nOkay, we'll be back in a few minutes with more jokes. In the meantime, feel free to get up and stretch your legs. Or go to the bathroom. Or whatever you need to do.\\n\\nWe'll be back soon!\", 'role': 'assistant', 'name': 'joe'}, {'content': 'I\\'m glad you enjoyed the joke! I love telling jokes, and it\\'s always great to see people laugh.\\n\\nI\\'m also happy to hear that you have a joke to share with me. I\\'m always looking for new jokes to add to my repertoire.\\n\\nYour joke about the talking dog is very funny! I especially like the way you played on the words \"conversa\" and \"dog.\" It\\'s a very clever joke.\\n\\nI\\'m also glad to hear that you\\'re enjoying our comedy duo. We work hard to make our shows funny and entertaining, and it\\'s always great to get positive feedback from our audience.\\n\\nI\\'m looking forward to hearing more of your jokes in the future. Keep up the good work!', 'role': 'user', 'name': 'cathy'}], summary='I\\'m glad you enjoyed the joke! I love telling jokes, and it\\'s always great to see people laugh.\\n\\nI\\'m also happy to hear that you have a joke to share with me. I\\'m always looking for new jokes to add to my repertoire.\\n\\nYour joke about the talking dog is very funny! I especially like the way you played on the words \"conversa\" and \"dog.\" It\\'s a very clever joke.\\n\\nI\\'m also glad to hear that you\\'re enjoying our comedy duo. We work hard to make our shows funny and entertaining, and it\\'s always great to get positive feedback from our audience.\\n\\nI\\'m looking forward to hearing more of your jokes in the future. Keep up the good work!', cost={'usage_including_cached_inference': {'total_cost': 0.0010345, 'gemini-pro': {'cost': 0.0010345, 'prompt_tokens': 467, 'completion_tokens': 534, 'total_tokens': 1001}}, 'usage_excluding_cached_inference': {'total_cost': 0.0010345, 'gemini-pro': {'cost': 0.0010345, 'prompt_tokens': 467, 'completion_tokens': 534, 'total_tokens': 1001}}}, human_input=[])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yM0ukel9-Cp9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}